# -*- coding: utf-8 -*-
"""Dicoding Final Project SIstem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JLROdc64j83-Ef_gjf2RVRlET0SfT1Ba

# Laporan Proyek Akhir Machine Learning Samuel Christian Hamdani

## Domain Proyek


---

###Latar Belakang

Perkembangan teknologi informasi yang pesat telah mendorong transformasi digital di berbagai bidang, termasuk dalam penyediaan layanan informasi dan hiburan. Salah satu bentuk transformasi tersebut adalah pemanfaatan sistem rekomendasi (recommender system) dalam membantu pengguna menemukan konten yang sesuai dengan minat atau kebutuhan mereka. Dalam konteks literasi dan pembelajaran, sistem rekomendasi buku menjadi salah satu solusi yang sangat relevan untuk mengatasi tantangan dalam memilih buku yang tepat di tengah melimpahnya pilihan yang tersedia.

Sistem rekomendasi buku adalah sistem yang dirancang untuk memberikan saran bacaan kepada pengguna berdasarkan sejumlah faktor, seperti interaksi sebelumnya, preferensi pribadi, atau karakteristik konten dari buku itu sendiri. Salah satu pendekatan populer yang digunakan dalam pengembangan sistem rekomendasi adalah content-based filtering menawarkan solusi yang lebih personal dengan menganalisis karakteristik atau fitur dari buku, seperti judul dan penuli. Sistem ini akan merekomendasikan buku yang memiliki kemiripan konten dengan buku yang pernah dibaca atau disukai oleh pengguna. Dengan demikian, meskipun pengguna baru dan belum memiliki banyak interaksi, sistem tetap dapat memberikan rekomendasi berdasarkan deskripsi atau atribut buku yang pernah mereka baca.

Melalui latar belakang ini, pengembangan model machine learning untuk sistem rekomendasi buku berdasarkan buku yang pernah dibaca menjadi topik yang penting dan relevan untuk diteliti. Dengan memanfaatkan data historis interaksi pengguna, diharapkan sistem yang dikembangkan mampu memberikan rekomendasi yang bersifat personal, adaptif, dan dapat meningkatkan kepuasan pengguna dalam menjelajahi dunia literasi.

### Problem Statement
1. Pengguna kesulitan menemukan buku yang sesuai dengan minat mereka karena terlalu banyak pilihan yang tersedia.

2. Rekomendasi yang bersifat umum atau acak sering kali tidak relevan dan mengurangi kepuasan pengguna.

3. Kurangnya pemanfaatan teknologi machine learning dalam sistem rekomendasi buku yang ada saat ini.

### Goals
1. Mengembangkan sistem rekomendasi buku berbasis machine learning.

2. Menganalisis dan memahami preferensi pengguna berdasarkan data buku yang pernah dibaca.

3. Meningkatkan relevansi dan akurasi rekomendasi buku untuk setiap pengguna.

### Solution Statement
1. Mengembangkan sistem rekomendasi buku berbasis machine learning dengan pendekatan content-based filtering, yaitu merekomendasikan buku yang memiliki kemiripan fitur (seperti judul, penulis) dengan buku yang pernah dibaca atau disukai oleh pengguna.

2. Menggunakan algoritma machine learning untuk mempelajari pola kesukaan pengguna dan menghasilkan rekomendasi yang bersifat personal.

3. Menerapkan teknik pemrosesan teks (seperti TF-IDF atau cosine similarity) untuk mengukur kemiripan antar buku berdasarkan kontennya.

# Data Preparation

---

Pada tahap ini dilakukan eksplorasi awal dan pembersihan terhadap data yang digunakan untuk membangun sistem rekomendasi buku. Dataset yang digunakan berisi beberapa fitur penting yang memengaruhi pengembangan sistem rekomendasi buku.

## Sumber Data
Sumber Dataset : https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Ratings.csv

Dataset yang diambil berasal dari sumber open source yaitu Kaggle yang menyimpan 3 dataset seperti macam-macam buku yang tersedia, rating pengguna, dan jumlah pengguna.

## Jumlah Data

1. Dataset Buku (books.csv)
  
    Jumlah Kolom : Pada dataset terdapat jumlah kolom sebanyak 8 kolom yang menyimpan data buku seperti:

  *   ISBN
  *   Book-TItle
  *   Book-Author
  *   Year-Of-Publication
  *   Publisher
  *   Image-URL-S
  *   Image-URL-M
  *   Image-URL-L

  Jumlah Baris : Sebanyak 271360 baris yang menyimpan data buku pada dataset ini.

2. Dataset Pengguna (users.csv)
  
    Jumlah Kolom : Pada dataset terdapat jumlah kolom sebanyak 3 kolom yang menyimpan data rating pengguna kepada buku yang pernah dibaca seperti:

  *   User-ID
  *   Location
  *   Age

  Jumlah Baris : Sebanyak 278858 baris yang menyimpan data buku pada dataset ini.

3. Dataset Rating (rating.csv)
  
    Jumlah Kolom : Pada dataset terdapat jumlah kolom sebanyak 3 kolom yang menyimpan data pengguna seperti:

  *   User-ID
  *   ISBN
  *   Book-Rating

  Jumlah Baris : Sebanyak 1149780 baris yang menyimpan data buku pada dataset ini.

## Kondisi Data:

1. Nilai Missing Value : Pada setiap dataset setelah dilakukan pemeriksaan nilai missing value didapatkan hasil bahwa dataset buku (books.csv) memiliki 3 baris yang menyimpan data kosong, pada dataset pengguna (users.csv) terdapat cukup banyak nilai kosong untuk usia pengguna, dan dataset rating (rating.csv) tidak memiliki data kosong. Dataset yang menyimpan nilai kosong akan dilakukan proses pembersihan.

2. Nilai Duplikat : Pada ketiga dataset, tidak terdapat data yang terduplikat, sehingga bisa disimpulkan bahwa ketiga dataset aman dari datad uplikat.

## Deskripsi Fitur
Berikut adalah penjelasan masing-masing fitur dalam masing-masing dataset:
1. Dataset Buku (books.csv)

  *   ISBN : Kode unik identifikasi untuk setiap buku (International Standard Book Number). Digunakan untuk menghubungkan data buku dengan data rating.
  *   Book-TItle : Judul lengkap dari buku. Berguna untuk menampilkan informasi buku pada antarmuka pengguna
  *   Book-Author : Nama penulis buku
  *   Year-Of-Publication : Tahun terbit buku.
  *   Publisher : Nama penerbit buku.
  *   Image-URL-S : URL gambar sampul buku dalam ukuran kecil (S)
  *   Image-URL-M : URL gambar sampul buku dalam ukuran sedang (M)
  *   Image-URL-L : URL gambar sampul buku dalam ukuran besar (L)

2. Dataset Pengguna (users.csv)
  *   User-ID : ID unik untuk masing-masing pengguna. Digunakan untuk menghubungkan data pengguna dengan data rating.
  *   Location : Lokasi pengguna
  *   Age : Usia pengguna

3. Dataset Rating (ratings.csv)
  *   User-ID : ID unik untuk masing-masing pengguna. Digunakan untuk menghubungkan data pengguna dengan data pengguna.
  *   ISBN : Kode unik identifikasi untuk setiap buku (International Standard Book Number). Digunakan untuk menghubungkan data buku dengan data rating.
  *   Book-Rating : Nilai rating yang diberikan pengguna terhadap buku yang pernah dibaca, dinilai dalam skala 0â€“10.

## Proses Persiapan Data
Dikarenakan model yang dikembangkan menggunakan pendekatan Content-Based Filtering, model akan dipakai untuk memberikan rekomendasi buku berdasarkan buku yang telah dibaca oleh pengguna berdasarkan penulis yang sama. Oleh karena itu, dilakukan proses persiapan data hanya pada dataset 'books.csv' karena menyimpan data buku dan penulis. Tahapan yang dilakukan dalam persiapan data diantaranya:

1. Load Dataset

  Dataset diupload dari google drive yang dimana sudah didownload dari sumber (Kaggle) agar dapat digunakan untuk perkembangan sistem rekomendasi.

2. Perubahan Nama Kolom

  Kolom-kolom pada masing-masing dataset akan dibuah menjadi bentuk yang dapat dibaca oleh sistem dan mudah untuk ditulis oleh pengembang.

3. Pembersihan Data dan Perubahan Tipe Data
  
  Dataset yang menyimpan data yang tidak sesuai akan dilakukan pembersihan agar dan Kolom-kolom yang tipe datanya tidak sesuai dengan data yang disimpan akan dilakukan pembersihan untuk memudahkan proses eksplorasi selanjutnya.

4. Distribusi Data

  Dibuatkan sebuah visualisasi untuk menghitung jumlah banyak buku yang ada dari tahun ke tahun, jumlah buku yang diterbit dari masing-masing penerbit, jumlah buku yang dibuat oleh penulis.

5. Penanganan Nilai Kosong

  Dataset diperiksa untuk mengetahui apakah terdapat nilai yang hilang atau tidak valid. Jika ditemukan, dilakukan penanganan seperti imputasi atau penghapusan baris.

6. Penanganan Nilai Duplikat

  Dataset diperiksa untuk mengetahui apakah terdapat nilai yang Duplikat. Jika ditemukan, dilakukan penanganan seperti penghapusan baris.

7. Transformasi Data
  
  Setelah dataset telah bersih, selanjutnya mengtransformasi data menjadi bentuk dictionary agar bisa dipakai dalam pengembangan model sistem rekomendasi.

## Import Library
Hal pertama yang dilakukan sebelum membuat model adalah mengimpor pustaka (library) yang digunakan dalam file ini berupa pandas, seaborn, matplotlib, dan sebagainya
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer

"""## Load Dataset

Selanjutnya, dataset diupload terlebih dahulu menggunakan fungsi 'read_csv' dari library pandas untuk memasukkan dataset kedalam environment agar digunakan dalam pengembangan model.
"""

books = pd.read_csv('/content/drive/MyDrive/Dicoding_ML/Reccomendation_System/Books_Reccomend/Books.csv')
ratings = pd.read_csv('/content/drive/MyDrive/Dicoding_ML/Reccomendation_System/Books_Reccomend/Ratings.csv')
users = pd.read_csv('/content/drive/MyDrive/Dicoding_ML/Reccomendation_System/Books_Reccomend/Users.csv')

"""Dari hasil pemanggilan dataset pada kode diatas, sistem sudah menyimpan data-data dan fitur yang tersimpan pada setiap dataset seperti data buku, rating, dan pengguna."""

books.info()

"""Dari output informasi dataset, terdapat informasi dataset dengan jumlah kolom sebanyak 8 kolom dengan tipe data object dan sebanyak 271360 data yang tersimpan."""

ratings.info()

"""Dari output informasi dataset, terdapat informasi dataset yang dapat diambil, seperti :
1. Terdapat 1 kolom yang menyimpan tipe data object. Ini digunakan untuk menyimpan data kode unik buku yang tersusun dari angka dan huruf.
2. Terdapat 2 kolom yang menyimpan tipe data integer. Ini digunakan untuk menyimpan ID-Pengguna dan rating yang dimasukkan.
3. Sebanyak 1.149.780 Data yang tersimpan pada dataset ratings.csv
"""

users.info()

"""Dari output informasi dataset, terdapat informasi dataset yang dapat diambil, seperti :
1. Terdapat 1 kolom yang menyimpan tipe data object. Ini digunakan untuk menyimpan data lokasi pengguna
2. Terdapat 1 kolom yang menyimpan tipe data integer. Ini digunakan untuk menyimpan ID-Pengguna dan rating yang dimasukkan.
3. Terdapat 1 kolom yang menyimpan tipe data float. Ini digunakan untuk menyimpan data usia pengguna
4. Sebanyak 278858 Data yang tersimpan pada dataset users.csv

## Exploratory Data Analysis (EDA)
Tahap selanjutnya ialah melakukan EDA guna mengenali data-data yang tersimpan pada dataset dan pendistribusian data. Tahapan EDA yang dilakukan disini adalah:
1. Perubahan Nama Kolom
2. Pembersihan Data dan Perubahan Tipe Data
3. Distribusi Data
4. Penanganan Nilai Kosong
5. Penanganan Data Duplikat

---


### Perubahan Nama Kolom
"""

books = books.rename(columns={
    'Book-Title': 'Title',
    'Book-Author': 'Author',
    'Year-Of-Publication': 'Year',
    'Image-URL-S': 'Image_S',
    'Image-URL-M': 'Image_M',
    'Image-URL-L': 'Image_L'
    })

"""Setelah dilakukan pemanggilan dataset dan melihat fitur yang tersedia, selanjutnya dilakukan perubahan nama kolom pada dataset 'books.csv' agar sistem dapat membaca kolom-kolom tersebut yang menyimpan data buku saat dianalisa dan memudahkan pengembang untuk menggunakan nama kolom tersebut"""

print('Banyak data buku: ', len(books.ISBN.unique()))
print('Banyak data pengarang: ', len(books.Author.unique()))
print('jenis tahun: ', books.Year.unique())
print('Jenis Penerbit: ', books.Publisher.unique())

"""Pada kode diatas, digunakan untuk mencari jumlah data yang tersimpan pada dataset seperti :
1. Jumlah buku sebanyak 271360
2. Jumlah pengarang sebanyak 102023
3. Rentang tahun terbit dari 0 s.d. 2050. Namun terdapat beberapa data yang seharusnya tidak dapat dikategorikan sebagai tahun terbit seperti 'DK Publishing Inc, dan Gallimard', hal ini akan dilakukan tahap pembersihan agar kolom tahun terbit terhindar dari data ini
4. Macam - macam penerbit yang tersimpan
"""

ratings = ratings.rename(columns={
    'User-ID': 'User_ID',
    'Book-Rating': 'Rating',
    })

"""Setelah dilakukan pemanggilan dataset dan melihat fitur yang tersedia, selanjutnya dilakukan perubahan nama kolom pada dataset 'rating.csv' agar sistem dapat membaca kolom-kolom tersebut yang menyimpan data rating pengguna."""

print('Banyaknya Pengguna: ', len(ratings.User_ID.unique()))
print('Jenis Rating: ', ratings.Rating.unique())

"""Pada kode diatas, digunakan untuk mencari jumlah data yang tersimpan pada dataset seperti :
1. Banyaknya pengguna sebanyak 105283 pengguna.
2. Nilai rating yang dimulai dari 0 s.d 10. Hal ini dapat diasumsikan bahwa buku yang tidak disukai oleh pengguna diberikan nilai 0 dan buku yang disukai oleh pengguna bernilai 10.
"""

users = users.rename(columns={'User-ID': 'User_ID'})

"""Kode diatas digunakan untuk mengubah nama kolom User-ID menjadi User_ID pada dataset 'users.csv' untuk memudahkan sistem membaca kolom dan membantu pengembang dalam menggunakan kolom tersebut"""

print('Banyaknya Pengguna: ', len(users.User_ID.unique()))
print('Lokasi Pengguna: ', users.Location.unique())

"""Pada dataset ini digunakan untuk mencari tahu detail pada dataset 'users.csv' seperti:
1. Jumlah Pengguna Sebanyak 278858 Pengguna
2. Lokasi Pengguna yang tersimpan dari berbagai neagar

### Pembersihan Data dan Perubahan Tipe Data
"""

# Mengubah kolom 'Year' menjadi tipe data string agar dapat memfilter nilai non-numerik
books['Year'] = books['Year'].astype(str)

# Daftar nilai tahun yang ingin dihapus
remove_publisher = ['DK Publishing Inc', 'Gallimard']

# Menghapus baris dengan nilai tahun yang tidak diinginkan
books = books[~books['Year'].isin(remove_publisher)]

# Mengubah kembali kolom 'Year' menjadi tipe data numerik (integer) setelah menghapus nilai non-numerik
books['Year'] = pd.to_numeric(books['Year'], errors='coerce')

print("Buku yang menyimpan tahun 'DK Publishing Inc' setelah dihapus: ", len(books[books['Year'] == 'DK Publishing Inc']))
print("Buku yang menyimpan tahun 'Gallimard' setelah dihapus: ", len(books[books['Year'] == 'Gallimard']))

"""Pada kode diatas digunakan untuk menghapus ambiguitas pada data yang tersimpan pada kolom tahun terbit yang menyimpan data penerbit. Hal ini dilakukan untuk menghindari kesalahan sebelum pengembangan model. Setelah model dijalankan didapatkan hasil bahwa data yang menyimpan jenis penerbit sebagai tahun terbit telah dihapus dari dataset."""

books['Year'] = books['Year'].astype(int)

"""Pada kode diatas, digunakan untuk mengubah tipe data untuk kolom 'Year' pada dataset 'books.csv' agar bisa dipakai untuk tahap distribusi data"""

# Menyimpan buku dalam rentang tahun 1950-2025
books = books[(books['Year'] >= 1950) & (books['Year'] <= 2025)].copy()

print("Jumlah buku dalam rentang tahun 1950-2025:", len(books))

"""Pada Kode diatas digunakan untuk memfilter data buku agar hanya mencakup buku-buku yang diterbitkan dalam rentang tahun 1950 hingga 2025. Hal ini dilakukan untuk menghapus data yang tidak relevan atau tidak valid, seperti tahun yang terlalu lama (sebelum 1950) atau data anomali (tahun di masa depan atau tidak masuk akal).

### Distribusi Data
"""

# Membuat visualisasi pembuatan buku berdasarkan tahun terbitnya

year_counts = books.groupby('Year')['Title'].count()
sort_year = year_counts.sort_values(ascending=False)
#Memanggil 10 tahun teratas yang membuat buku paling banyak
top_10_years = sort_year.head(10)
# Plot 10 tahun teratas dan buku yang ditulis oleh penulis
plt.figure(figsize=(12, 6))
top_10_years.plot(kind='bar')
plt.xlabel('Tahun Terbit')
plt.ylabel('Jumlah Buku')
plt.title('10 Tahun Teratas Berdasarkan Jumlah Buku Yang Diterbit')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Pada kode diatas, digunakan untuk menghasilkan visualisasi untuk melihat 10 tahun teratas yang membuat buku paling banyak. Dari hasil visualisasi, dijelaskan bahwa tahun 2002 adalah tahun dengan jumlah buku terbanyak diikuti oleh tahun 1999, 2001, dan 2000."""

# Membuat visualisasi 10 penerbit teratas yang paling banyak membuat buku

publisher_counts = books.groupby('Publisher')['Title'].count()
sort_publisher = publisher_counts.sort_values(ascending=False)
#Memanggil 10 author teratas yang membuat buku paling banyak
top_10_publisher = sort_publisher.head(10)
# Plot 10 penerbit teratas dan buku yang ditulis oleh penulis
plt.figure(figsize=(12, 6))
top_10_publisher.plot(kind='bar')
plt.xlabel('Nama Penerbit')
plt.ylabel('Jumlah Buku')
plt.title('10 Penerbit Teratas Berdasarkan Jumlah Buku Yang Diterbit')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Pada kode diatas, digunakan untuk menghasilkan visualisasi untuk melihat 10 penerbit teratas yang membuat buku paling banyak. Dari hasil visualisasi dijelaskan bahwa, Harlequin merupakan penerbit dengan jumlah buku terbanyak yang diterbitkan, diikuti oleh Silhouette, Pocket, dan sebagainya."""

# Membuat visualisasi 10 penulis teratas yang paling banyak membuat buku

author_counts = books.groupby('Author')['Title'].count()
sort_authors = author_counts.sort_values(ascending=False)
#Memanggil 10 author teratas yang membuat buku paling banyak
top_10_authors = sort_authors.head(10)

# Plot 10 penulis teratas dan buku yang dibuat oleh penulis
plt.figure(figsize=(12, 6))
top_10_authors.plot(kind='bar')
plt.xlabel('Nama Penulis')
plt.ylabel('Jumlah Buku')
plt.title('10 Penulis Teratas Berdasarkan Jumlah Buku Yang Ditulis')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Pada kode diatas, digunakan untuk menghasilkan visualisasi untuk melihat 10 penulis buku teratas yang membuat buku paling banyak. Dari hasil visualisasi dijelaskan bahwa, Agatha Christie merupakan penulis dengan jumlah buku terbanyak yang diterbitkan, diikuti oleh William Shakespeare dan Stephen King. Penulis-penulis lainnya yang juga mendominasi adalah Ann M. Martin, Francine Pascal, dan Carolyn Keene.

### Penanganan Nilai Kosong (Missing Value)
"""

print("Jumlah Missing Value pada dataset books:\n",books.isnull().sum())
print("===============")
print("Jumlah Missing Value pada dataset ratings:\n",ratings.isnull().sum())
print("===============")
print("Jumlah Missing Value pada dataset users:\n",users.isnull().sum()) ##Gapake dataset ini karena kebanyakan data missing value

"""Pada kode diatas dijalankan untuk mencari tahu jumlah nilai kosong yang ada pada masing-masing dataset, dari hasil penjalan kode tersebut disimpulkan bahwa:
1. Pada dataset 'books.csv' sebanyak 3 baris yang menyimpan data kosong untuk nama penulis, nama penerbit, dan link gambar buku berukuran besar.
2. Pada dataset 'ratings.csv' tidak terdapat nilai kosong.
3. Pada dataset 'users.csv' sebanyak 110762 baris yang menyimpan data kosong untuk data umur pengguna.

Dikarenakan dataset yang akan dipakai untuk pengembangan model yaitu 'books.csv' hanya akan dilakukan pembersihan data yang kosong untuk dataset 'books.csv' saja.
"""

books.dropna(inplace=True)
print("Jumlah Missing Value pada dataset books:\n",books.isnull().sum())

"""Pada kode diatas digunakan untuk menghapus data yang menyimpan nilai kosong pada dataset 'books.csv', dari hasil penjalanan kode didapati hasil bahwa seluruh data yang menyimpan nilai kosong telah dihapus dan sudah bersih dari nilai kosong.

### Penanganan Nilai Duplikat
"""

print("Jumlah data duplikat pada dataset books:",books.duplicated().sum())
print("Jumlah data duplikat pada dataset ratings:",ratings.duplicated().sum())
print("Jumlah data duplikat pada dataset users:",users.duplicated().sum())

"""Pada kode diatas digunakan untuk mencari tahu apakah terdapat data yang terduplikat pada dataset. Dari hasil penjalanan kode tersebut didapati hasil bahwa ketiga dataset tidak terdapat data duplikat sehingga bisa diasumsikan bahwa seluruh dataset tersebut aman dari duplikasi data.

## Transformasi Data
"""

books.shape

"""Pada kode diatas, digunakan untuk meiihat jumlah baris dan kolom yang tersisa setelah proses pembersihan dataset. Dari kode diatas, diberitahukan bahwa tersisa 266430 baris data setelah pembersihan dan terdapat 8 kolom yang masih tersimpan pada dataset 'books.csv'."""

books = books[:30000]
books.info()

"""Pada kode diatas digunakan untuk menyimpan jumlah baris dataset 'books.csv' sebanyak 30.000 baris, hal ini dikarenakan jumlah data pada dataset 'books.csv' cukup banyak sehingga alokasi memori RAM tidak cukup untuk memproses seluruh data."""

# Membuat menjadi list
isbn = books['ISBN'].tolist()
title = books['Title'].tolist()
author = books['Author'].tolist()
year = books['Year'].tolist()
publisher = books['Publisher'].tolist()
image_s = books['Image_S'].tolist()
image_m = books['Image_M'].tolist()
image_l = books['Image_L'].tolist()

"""Pada kode diatas, selanjutnya mengonversi format semua kolom dataset yang tersimpan menjadi bentuk list agar data bisa dipakai saat pengembangan model sistem rekomendasi buku."""

# Membuat menjadi dictionary
books = pd.DataFrame({
    'isbn': isbn,
    'title': title,
    'author': author,
    'year': year,
    'publisher': publisher,
    'image_s': image_s,
    'image_m': image_m,
    'image_l': image_l,
})
books.head(5)

"""Setelah dibuatkan menjadi bentuk list, tahap selanjutnya adalah  membuat dictionary untuk menentukan pasangan key-value pada dataset 'books.csv'

# Model Development

Setelah data yang digunakan telah selesai untuk dibersihkan dan bisa dipakai, selanjutnya adalah pengembangan model machine learning dengan pendekatan Content-Based Filtering untuk membuat sistem rekomendasi buku berdasarkan buku dengan penulis (author) yang sama menggunakan library TfIdVectorizer dan Cosine Similarity.

Penjelasan pendekatan Content-Based Filtering:

**Cara kerja:**

1. Ekstraksi Fitur: Sistem mengekstrak fitur dari item, seperti penulis, genre, kata kunci, deskripsi, dll.

2. Representasi Vektor: Fitur-fitur tersebut dikonversi menjadi bentuk numerik, biasanya menggunakan metode seperti TF-IDF atau word embeddings.

3. Perhitungan Kemiripan: Sistem menghitung kemiripan antara item menggunakan metrik seperti cosine similarity.

4. Rekomendasi: Sistem merekomendasikan item lain yang paling mirip dengan item yang pernah disukai oleh pengguna.

**Kelebihan :**
1. Tidak tergantung data pengguna lain: Sistem dapat bekerja dengan baik meskipun hanya ada sedikit pengguna (cocok untuk cold-start user).

2. Personalized: Rekomendasi sangat sesuai dengan preferensi individu karena berdasarkan riwayat pengguna itu sendiri.

3. Transparansi: Lebih mudah menjelaskan alasan rekomendasi ("buku ini direkomendasikan karena mirip dengan buku X yang Anda sukai").

**Kekurangan:**
1. Kurang mampu memberikan keberagaman: Sistem cenderung merekomendasikan item yang sangat mirip, sehingga bisa membatasi eksplorasi.

2. Terbatas pada fitur item: Jika fitur kurang informatif atau tidak lengkap, kualitas rekomendasi akan menurun.

3. Cold-start item: Tidak dapat merekomendasikan item baru jika belum memiliki informasi kontennya.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data author
tf.fit(books['author'])
tf.get_feature_names_out()

"""Pada kode di atas menggunakan library TfidfVectorizer untuk mengubah data teks pada kolom author menjadi representasi numerik berbasis TF-IDF. Langkah ini dilakukan untuk menghitung seberapa penting kata (dalam hal ini nama penulis) dalam kumpulan data. Fungsi fit() digunakan untuk mempelajari skor IDF dari data penulis, sementara get_feature_names_out() digunakan untuk menampilkan daftar nama penulis yang telah diproses menjadi fitur."""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(books['author'])
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Pada kode diatas digunakan untuk melakukan transformasi data teks pada kolom author menjadi matriks numerik menggunakan metode TF-IDF. Fungsi fit_transform() digunakan untuk menghitung bobot TF-IDF dari setiap nama penulis dan mengubahnya menjadi matriks vektor fitur. Hasilnya disimpan dalam variabel tfidf_matrix. Kemudian, tfidf_matrix.shape digunakan untuk melihat ukuran matriks, yang menunjukkan jumlah buku dan jumlah fitur unik  yang dihasilkan dari nama-nama penulis yang nantinya akan digunakan dalam proses perhitungan kesamaan antar buku untuk sistem rekomendasi berbasis konten."""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Pada kode diatas, tfidf_matrix.todense() digunakan untuk mengubah hasil transformasi TF-IDF yang awalnya dalam bentuk sparse matrix menjadi dense matrix atau matriks penuh. Sparse matrix hanya menyimpan nilai yang bukan nol untuk menghemat memori."""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=books.title
).sample(10, axis=1,replace=True).sample(10, axis=0)

"""Pada kode diatas, digunakan untuk menampilkan sample acak sebanyak 10 sample dari matriks TF-IDF yang telah diubah menjadi DataFrame, sehingga bisa dilakukan pengecekan isi secara visual dan memahami bobot kata dari penulis terhadap masing-masing buku."""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Pada kode diatas, digunakan untuk mengukur tingkat kemiripan antar buku berdasarkan penulisnya dengan menggunakan metode cosine similarity. Fungsi cosine_similarity(tfidf_matrix) menghitung kemiripan antar setiap pasangan buku dari matriks TF-IDF yang merepresentasikan nama penulis. Hasilnya disimpan dalam variabel cosine_sim, berupa matriks dua dimensi di mana setiap nilai menunjukkan seberapa mirip satu buku dengan buku lainnya berdasarkan penulisnya."""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama judul buku
cosine_sim_df = pd.DataFrame(cosine_sim, index=books['title'], columns=books['title'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap judul buku
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Pada kode diatas, digunakan untuk mengorganisasi hasil perhitungan kemiripan antar buku ke dalam bentuk DataFrame berdasarkan nama buku dari dataset 'books.csv' sehingga lebih mudah dibaca dan dianalisis hal ini dilakukan guna mempermudah eksplorasi dan validasi hasil perhitungan kemiripan antar buku, yang nantinya bisa digunakan dalam sistem rekomendasi buku berbasis content-based filtering."""

def books_reccomendation_cbf(book_title, similarity_data=cosine_sim_df, items=books[['title', 'author']], k=5):

    # Mengambil data similarity antara book_title dengan seluruh buku
    if book_title not in similarity_data.columns:
        print(f"Error: Book '{book_title}' not found in the similarity data.")
        return pd.DataFrame() # Return an empty DataFrame

    similarity_scores = similarity_data.loc[:, book_title].to_numpy()

    # Menentukan indeks dengan similarity terbesar menggunakan argpartition
    book_similarity = similarity_data[book_title]

    # Mengurutkan rekomendasi buku berdasarkan skor similairtas tertinggi sebanyak k buku
    sorted_similarity = book_similarity.sort_values(ascending=False)
    top_k_plus_1 = sorted_similarity.head(k + 1)

    # Mengambil judul buku dan skor similaritas
    closest_titles = top_k_plus_1.index.tolist()
    closest_scores = top_k_plus_1.values

    # Membuat DataFrame sementara dari judul dan skor
    temp_df = pd.DataFrame({
        'Book_Recommendation': closest_titles,
        'Similarity': closest_scores
    })

    # Mengecualikan buku yang sama dengan input
    result = temp_df[temp_df['Book_Recommendation'] != book_title]

    # Mengambil top k rekomendasi setelah mengecualikan input buku
    result = result.head(k)

    # Merge dengan informasi item untuk mendapatkan Author
    result = result.merge(items, left_on='Book_Recommendation', right_on='title') \
                   .drop(columns=['title']) \
                   .rename(columns={'author': 'Author'})

    # Mengembalikan top k rekomendasi
    return result.head(k)

"""Pada kode diatas, dibuatkan sebuah fungsi books_reccomendation_cbf untuk memberikan rekomendasi buku berbasis content-based filtering berdasarkan kemiripan judul buku. Fungsi ini terlebih dahulu memeriksa apakah judul buku yang diminta terdapat dalam data, lalu menghitung skor kemiripan (similarity) antara buku tersebut dengan semua buku lainnya menggunakan matrix similarity. Setelah itu, fungsi mengurutkan skor dari yang tertinggi, mengecualikan buku input dari hasil, dan mengambil top-k buku yaitu berjumlah 5 dengan skor kemiripan tertinggi. Hasil akhirnya adalah DataFrame yang berisi judul buku rekomendasi, nilai kemiripan, dan nama penulis dari buku-buku yang paling mirip.

# Validation

Setelah model telah selesai dikembangkan, selanjutnya melakukan tes validasi guna mencari tahu apakah model yang dikembangkan untuk memberikan rekomendasi 5 buku berdasarkan penulis yang sama
"""

# Mendapatkan rekomendasi buku berdasarkan judul
books_reccomendation_cbf('El Hombre Que Susurraba Al Oido De Los Caballos')

"""Pada kode diatas, setelah model dikembangkan selanjutnya adalah memeriksa apakah model dapat memberikan rekomendasi buku yang akurat berdasarkan penulis yang sama. Dari hasil output diatas, didapati hasil bahwa model memberikan referensi kelima buku lain dari penulis dengan nama yang sama yaitu Nicholas Evans. Oleh karena itu, dapat disimpulkan bahwa model yang dibangun sudah bisa dipakai untuk memberikan rekomendasi buku berdasarkan penulis yang sama.

## Hubungan Business Understanding
| **Aspek**                                                                                                       | **Evaluasi**                                                                                                                                                                                                |
| --------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Problem 1: Pengguna kesulitan menemukan buku yang sesuai dengan minat mereka karena terlalu banyak pilihan**  | Model mampu menyaring dan merekomendasikan buku yang relevan berdasarkan kemiripan dengan buku yang pernah dibaca atau disukai, sehingga membantu pengguna menemukan buku yang sesuai dengan preferensinya. |
| **Problem 2: Rekomendasi yang bersifat umum atau acak sering kali tidak relevan**                               | Dengan pendekatan content-based filtering dan perhitungan kemiripan menggunakan cosine similarity, sistem dapat memberikan rekomendasi yang lebih personal dan tepat sasaran.                               |
| **Problem 3: Kurangnya pemanfaatan teknologi machine learning dalam sistem rekomendasi buku yang ada saat ini** | Sistem yang dibangun telah mengimplementasikan teknik TF-IDF dan cosine similarity secara efektif untuk memahami kemiripan antar buku, memanfaatkan teknologi machine learning secara langsung.             |
| **Goal 1: Mengembangkan sistem rekomendasi buku berbasis machine learning**                                     | Sistem berhasil dibangun dengan pendekatan content-based filtering menggunakan data buku, penulis, dan tingkat kesamaan antar konten.                                                                       |
| **Goal 2: Menganalisis dan memahami preferensi pengguna berdasarkan data buku yang pernah dibaca**              | Sistem dapat mengidentifikasi dan menyarankan buku lain berdasarkan kemiripan penulis dengan yang pernah dibaca oleh pengguna.                                                                              |
| **Goal 3: Meningkatkan relevansi dan akurasi rekomendasi buku untuk setiap pengguna**                           | Output sistem memberikan hasil dengan skor kemiripan yang tinggi, menunjukkan bahwa sistem menghasilkan rekomendasi yang relevan dan akurat.                                                                |

## Solusi
Solusi yang dikembangkan berupa sistem rekomendasi buku berbasis content-based filtering terbukti mampu menyajikan daftar rekomendasi buku yang sesuai berdasarkan konten buku yang telah dibaca, khususnya melalui analisis penulis. Dengan menggunakan pendekatan TF-IDF Vectorizer dan cosine similarity, sistem ini memberikan hasil yang akurat dan relevan tanpa memerlukan data eksplisit dari pengguna. Hasilnya, pengguna dapat dengan mudah menemukan buku yang sesuai dengan minatnya, menghemat waktu dalam pencarian, serta meningkatkan kepuasan terhadap pengalaman membaca.

Dengan demikian, tahap evaluasi menunjukkan bahwa model rekomendasi yang dibangun tidak hanya menjawab permasalahan utama pengguna, tetapi juga memberikan nilai tambah nyata dalam konteks personalisasi dan efisiensi dalam menemukan referensi bacaan yang relevan.

"""